{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "class Scraper:\n",
    "    def __init__(self, league:str, url:str='https://www.besoccer.com/competition', year: int=2022) -> None:\n",
    "        pathlib.Path(f'Data/Results/{league}').mkdir(parents=True, exist_ok=True) \n",
    "        pathlib.Path(f'Data/To_Predict/{league}').mkdir(parents=True, exist_ok=True) \n",
    "        self.league = league\n",
    "        self.url = url\n",
    "        self.year = year\n",
    "        r = requests.get(f\"{self.url}/scores/{self.league}/{self.year}\")\n",
    "        time.sleep(1)\n",
    "        soup = bs(r.content, 'html.parser')\n",
    "        matchday_str = soup.find('div', {'class': 'panel-title'}).text\n",
    "        self.matchday = [int(s) for s in matchday_str.split() if s.isdigit()][0]\n",
    "\n",
    "    def get_previous_matches(self):\n",
    "        results = {'Home_Team': [], 'Away_Team': [], 'Result': [], 'Link': [], 'Season': [], 'Round': [], 'League': []}\n",
    "        for matchday in tqdm(range(1, self.matchday)):\n",
    "            r = requests.get(f\"{self.url}/scores/{self.league}/{self.year}/round{matchday}\")\n",
    "            time.sleep(1)\n",
    "            soup = bs(r.content, 'html.parser')\n",
    "            matches_box = soup.find('div', {'class': 'panel-body p0 match-list-new'})\n",
    "            matches = matches_box.find_all('a', {'class': 'match-link'})\n",
    "            for match in matches:\n",
    "                home_team = match.find('div', {'class': 'team-info ta-r'}).find('div', {'class': 'name'}).text.strip()\n",
    "                away_team = match.find_all('div', {'class': 'team-info'})[1].find('div', {'class': 'name'}).text.strip()\n",
    "                home_score = match.find('div', {'class': 'marker'}).find('span', {'class': 'r1'}).text.strip()\n",
    "                away_score = match.find('div', {'class': 'marker'}).find('span', {'class': 'r2'}).text.strip()\n",
    "                results['Home_Team'].append(home_team)\n",
    "                results['Away_Team'].append(away_team)\n",
    "                results['Result'].append(f'{home_score}-{away_score}')\n",
    "                results['Link'].append(match.get('href'))\n",
    "                results['Season'].append(self.year)\n",
    "                results['Round'].append(matchday)\n",
    "                results['League'].append(self.league)\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv(f'Data/Results/{self.league}/Results_{self.year}_{self.league}.csv')\n",
    "    \n",
    "    def get_next_matches(self):\n",
    "        results = {'Home_Team': [], 'Away_Team': [], 'Link': [], 'Season': [], 'Round': [], 'League': []}\n",
    "        elo_dict = {}\n",
    "        r = requests.get(f\"{self.url}/scores/{self.league}/{self.year}/round{self.matchday + 1}\")\n",
    "        time.sleep(1)\n",
    "        soup = bs(r.content, 'html.parser')\n",
    "        matches_box = soup.find('div', {'class': 'panel-body p0 match-list-new'})\n",
    "        matches = matches_box.find_all('a', {'class': 'match-link'})\n",
    "        self.matches = matches\n",
    "\n",
    "        for match in matches:\n",
    "            home_team = match.find('div', {'class': 'team-info ta-r'}).find('div', {'class': 'name'}).text.strip()\n",
    "            away_team = match.find_all('div', {'class': 'team-info'})[1].find('div', {'class': 'name'}).text.strip()\n",
    "            results['Home_Team'].append(home_team)\n",
    "            results['Away_Team'].append(away_team)\n",
    "            results['Link'].append(match.get('href'))\n",
    "            results['Season'].append(self.year)\n",
    "            results['Round'].append(self.matchday + 1)\n",
    "            results['League'].append(self.league)\n",
    "            \n",
    "        for link in results['Link']:\n",
    "            time.sleep(3)\n",
    "            r = requests.get(link + '/analysis')\n",
    "            soup = bs(r.content, 'html.parser')\n",
    "            elo_box = soup.find('div', {'class': 'panel-body pn compare-data'})\n",
    "            elo_row = elo_box.find_all('tr')[1]\n",
    "            home_elo = elo_row.find('td', {'class': 'team1-c'}).text.strip()\n",
    "            away_elo = elo_row.find('td', {'class': 'team2-c'}).text.strip()\n",
    "            elo_dict[link] = {'Elo_home': home_elo, \n",
    "                              'Elo_away': away_elo}\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv(f'Data/To_Predict/{self.league}/Results_{self.year}_{self.league}.csv')\n",
    "        with open(f'Data/To_Predict/{self.league}/elo_dict.pkl', 'wb') as f:\n",
    "            pickle.dump(elo_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "primera_division = Scraper('primera_division')\n",
    "primera_division.get_next_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(primera_division.get_next_matches())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8b4105202d2e4bbdb618e4640bd5a7b72dbac3883604a8f92601b04b48cfdf0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('AiCoreFootballProject': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
